{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "““classifier.ipynb”的副本”的副本",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengcheny/Keras_Python/blob/master/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOmmux7Z9F-w",
        "colab_type": "text"
      },
      "source": [
        "#Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiOxyt13KS_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "93f659ad-094c-4f33-e483-38f9ec784b04"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
        "# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# data pre-processing\n",
        "X_train = X_train.reshape(-1, 1,28, 28)/255.\n",
        "X_test = X_test.reshape(-1, 1,28, 28)/255.\n",
        "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Another way to build your CNN\n",
        "model = Sequential()\n",
        "\n",
        "# Conv layer 1 output shape (32, 28, 28)\n",
        "model.add(Convolution2D(\n",
        "    batch_input_shape=(None, 1, 28, 28),\n",
        "    filters=32,\n",
        "    kernel_size=5,\n",
        "    strides=1,\n",
        "    padding='same',     # Padding method\n",
        "    data_format='channels_first',\n",
        "))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling layer 1 (max pooling) output shape (32, 14, 14)\n",
        "model.add(MaxPooling2D(\n",
        "    pool_size=2,\n",
        "    strides=2,\n",
        "    padding='same',    # Padding method\n",
        "    data_format='channels_first',\n",
        "))\n",
        "\n",
        "# Conv layer 2 output shape (64, 14, 14)\n",
        "model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
        "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
        "\n",
        "# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Fully connected layer 2 to shape (10) for 10 classes\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Another way to define your optimizer\n",
        "adam = Adam(lr=1e-4)\n",
        "\n",
        "# We add metrics to get more results you want to see\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training ------------')\n",
        "# Another way to train the model\n",
        "model.fit(X_train, y_train, epochs=1, batch_size=64,)\n",
        "\n",
        "print('\\nTesting ------------')\n",
        "# Evaluate the model with the metrics we defined earlier\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print('\\ntest loss: ', loss)\n",
        "print('\\ntest accuracy: ', accuracy)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0813 18:06:49.446894 140199975020416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training ------------\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 291s 5ms/step - loss: 0.2706 - acc: 0.9263\n",
            "\n",
            "Testing ------------\n",
            "10000/10000 [==============================] - 25s 3ms/step\n",
            "\n",
            "test loss:  0.10061754385381937\n",
            "\n",
            "test accuracy:  0.9691\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}